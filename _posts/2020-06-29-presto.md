---
layout: post
title:  "Presto - Distributed SQL Query Engine on Multiple Sources"
date:   2020-08-15T11:11:11
author: the-realest-one
categories: DataPlatform
tags:	SQL Query DB Analysis OLAP
cover:  "/assets/North.jpg"
use_math: true
---

# Presto

링크: https://blog.openbridge.com/what-is-facebook-presto-presto-database-or-prestodb-a-powerful-sql-query-engine-77d4c4a66d4

페이스북이 프레스토 프로젝트의 목적? 시초? 에 대해 말한 글이다

For the analysts, data scientists, and engineers who crunch data derive insights,
and work to continuously improve our products,
the performance of queries against our data warehouse is important.
Being able to run more queries and get results faster improves their productivity.
 
프레스토를 만든 목적이, 데이터 쿼리의 속도 향상에 있음을 바로 알게 해준다.

페이스북은 또 중요한 말을 하나 한다.

In contrast, the Presto engine does not use MapReduce.
It employs a *custom query and execution engine* with operators designed to support SQL semantics.
In addition to *improved scheduling*, all processing is *in memory* and *pipelined across the network* between stages.
This avoids unnecessary I/O and associated latency overhead.

대충 중요한 말들을 기울임체로 표기했다. 커스텀 쿼리 엔진은 무엇인지, 
improved scheduling 이란 무엇인지 궁금한 것이 많다!
in memory 로 된다는 것은 중요한 키워드고, 파이프라이닝은 또 어떻게 될런지 알아봐야겠다.

key feauture of Presto:
크기가 다른 다양한 소스들에 쿼리를 할 수 있게 해준다!
hadoop HDFS, Amazon S3, HBase, Mysql Postgresql, Redshift 등등

2 번 째 goal: support ANSI SQL. 그리고 다양한 조인들, 서브쿼리, 디스틴트 카운트 등등 sql 문법을 지원.

이런 goal 들과 철학이 만들어서 모여진 프레스토를 정리해보면
SQL query proxy 처럼 작동하고, 여러 데이터소스들에서 쿼리가 가능하고,
SQL 문법을 지원하고 쿼리가 빠른 DB 이다.

??
링크의 Facebook Presto Performance 에 보면,
tableau 에 관한 내용이 있음.
그런데, 우리 회사는 지금 태블로에서 레드시프트로 쿼리하는 게 찍히는 게 있는데
이거 보면 빨라지지 않을까?

# Use Case in Lyft

링크: https://eng.lyft.com/presto-infrastructure-at-lyft-b10adb9db01

Lyft 에서는 왜 presto 를 썼는가

원래는 여러 대시보드들의 백엔드로 Amazon Redshift 를 썼다고 한다.
그런데, Redshift 는 data storage 와 compute 가 같이 묶여있음.
그런데 2017 년 당시 Lyft 는 데이터가 기하급수적으로 늘어나고 있었음. -> storage scaling 이 자주 일어남.
data 와 compute 가 coupled 되어 있었기 때문에, storage scaling 이나 maintenance, upgrade 등이 일어나면,
쿼리가 굉장히 느려졌음.
그래서 data 와 compute 가 분리된 것을 찾다가, presto 를 이용하게 됨!

Lyft 에서 쓰는 것들:

1. **Query-log Plugin**: 새로운 쿼리가 오면, 위험한 쿼리들은 막는 컴포넌트.
그리고, *queryCreated* 와 *queryCompleted* timestamp 등 로그를 찍음.
이를 통해, 성공률, 레이턴시, 실패와 실패 이유 등을 분석함.

1. **Presto UDF**: 프레스토를 쓰는 유저들(Data Scientists, Data Engineers, Business Analyst 등)
들이 custom UDF 들을 만들 수 있게 하는 컴포넌트.

1. **Python-based stats collection**: 정확히는 잘 모르겠지만, 시스템 메트릭들을 계산하고 저장하는 것 같다.
이런 metric 들을 실시간으로 계산하고 체크하면서, 시스템에 이상이 생기거나 하면 alert 를 쏘거나 pagerduty 로 on-call 하는 듯.

1. **Test suits**: 새로운 버전의 Presto 를 프로덕션 환경에 올리기 전에, 여러 테스트를 돌림.

1. **PrestoInfra**: collection of configurations and scripts to build and release deploy-able artifacts and saltstack scripts to rollout environment specific deployments.
라고 써져 있는데.... 뭔 소리인지 잘 감이 안 잡힌다. 이번 엔지니어링 리딩에서 질문을 해봐야겠다. // TODO

1. **PrestoProxy**: lyft specific routing 과 여러 override 들이 들어간 customized presto-gateway


## Presto production environment and configurations in Lyft

리프트는 여러 개의 프레스토 클러스터를 쓴다고 한다 ㄷㄷ.
각 클러스터에는 한 개의 presto gateway 가 있어서 로드를 분산하고, 워커노드는 100 개 이상 있다고 한다.
자세한 config 는 링크 참조.

node 에 대한 config, 한 쿼리의 max memory, max run time 등 여러 config 들도 링크에 있다.
어떤 자바 버전과 JVM config 를 presto node 에 썼는지도 나와 있으니 링크 참조.

### Presto Node Recycle in Lyft

이건 Lyft 의 경험에 나온 디자인인데, 정말 꿀팁인 거 같아서 따로 적는다.
Lyft 가 presto 클러스터를 운영하면서, 문제를 발견했다고 한다.
바로 클러스터가 오래되고, 많은 쿼리가 그 클러스터에서 실행될 수록 pause time 이 늘어났다는 것이다.
그리고 새로운 클러스터가 쿼리 퍼포먼스도 더 좋다고한다.
그래서, 각 프레스토 클러스터에서, 매 24 시간마다 모든 노드를 새로 갈아끼우게 설정했다고 한다.

## Presto Gateway in Lyft

Presto-Gateway is a stateful load-balancer, proxy and router for multiple presto clusters,
it provides transparent access to underlying presto-backend without changing the protocol.

Presto-Gateway 란 무엇인가? 프레스토 클러스터의 stateful 로드밸런서이자 프록시이자 라우터이다.
아마 따로 검색해도 안 나올 듯 하다. 왜냐면, Lyft 에서 특정 문제 해결을 위해 자체적으로 만든 것이기 때문이다.

자 하나하나 따져보자. 왜 presto gateway 는 proxy 여야 했을까?

1. External BI Tools
Lyft 에서 쓰는 BI tool 들이 Lyft 것이 아닌 외부 툴이기 때문이다.
외부 툴이기 때문에 BI tool 들은 Lyft network 안의 agent 를 통해 presto 를 접근하고 있었다.
그런데 이 agent 들은 HTTP-redirects 를 따르기는 불가능했다.

2. Scalability and Changeability
이것은 내 추측이긴 한데, 일단 써 보겠다. 외부 (BI Tool 들 혹은 사람의 쿼리) 가 직접 presto cluster 에 쿼리하고 있는 상황이었다.
그런데 이 presto cluster 는 여러개로 늘어날 수 있다.
그리고 BI tool 들 또한 바뀌거나, 새로운 툴이 추가되거나 등등이 가능하다.
그렇기 때문에 앞에 gateway 를 두어 gateway -> presto cluster 는 protocol 을 고정해둠으로써,
Scalability and Changeability 를 얻을 수 있기를 기대했을 것이다.


자 그 다음은 load balancer 이자 router. 왜 load balancer 이자 router 가 필요했을까?

맨 처음에는 클러스터가 하나였다. 여러 개의 BI tool 들이 한 클러스터로 요청을 보냈다.
이에 outage 도 많이 나고, no-downtime update 도 힘들었다.
그 다음으로는 cluster 를 2 ~ 3 개 두고, BI tool 과 클러스터 하나를 일대일 매칭시켰다.
문제가 어느정도는 좋아졌다. 하지만 어느 한 클러스터는 대기열이 많이 걸려 막혀 있는데 다른 클러스터는 놀고 있는 상황이 발견되었다.
또 여전히 no downtime update 가 불가능한 문제가 있었다.
이에, load balanacer 이자 router 가 필요했다.

Presto Gateway in Lyft 는 3 가지 구성요소를 가진다: BaseApp, ProxyServer, Gateway.
각각이 무엇인지를 쓸 이유는 없을 듯 하다. 필요하면 링크를 보는 거로.

### Cost aware scaling to meet query demand in Lyft

좋아. Presto Gateway 까지 다 만들었고 쿼리를 신나게 하고 있었다.
그리고, working hour 에 직원들이 일을 열심히 해서 쿼리를 많이 날렸다.
쿼리를 많이 날리니 클러스터가 부족했고, 필요한 만큼 계속 클러스터의 개수와 크기를 늘려나갔다.

위까지만 보면, 그래도 분석을 위해 돈 많이 쓰게 해주는 좋은 회사이다.
하지만, 돈은 정말 많이 나갈 것이다. 그리고 워커 노드와 클러스터를 늘리는 것이 능사가 아니라는 것을 늘리다보면 깨닫게 된다.

Lyft 도 이 문제를 인식 했을 것이다.
그리고 나서 쿼리를 모니터링 해보니, 대부분의 쿼리가 working hour 에 이루어지고, 특정 시간에만 요청이 쏟아짐을 깨달았다.

이에 업무 외 시간에 자동으로 인프라의 50 % 를 없애는 작업을 진행하여
무려 30 % 의 total cost 를 줄였다고 한다. 정말 어마어마하다!

그 다음부터는 Lyft 가 presto 관련해 open source contribute 한 것들에 대해 말한다.
어느정도 자랑이 섞여 있는 것 같은데 ㅋㅋㅋ 그래도 자랑할 만한 것들인 건 확실하다.
나는 google sheet 관련한 단락은 빼고 글을 적겠다.

### Superset Presto Integration Improvements in Lyft

보통 sql based workflow 와 파이프라인은 유저 편의성에 문제가 있다고 한다.
쿼리를 실행시킨 후에야만 어디가 틀렸는지 알려주고, 어떻게 고칠지 제안해준다고 한다.
이는 분석가와 데이터 사이언티스트들에게 정말 큰 스트레스이다.
왜냐면 데이터 양이 많아질 수록, 쿼리가 한 번 돌아가는데 시간이 오래 걸리기 때문이다.
일하다보면 쿼리 돌아가는 거 기다리는 것만 한 세월인 경우가 정말 많다.

이에 Lyft 는 `Apache Superset — pre execution deep query validation component` 를 도입했다고 한다.
Lyft 에서 새로 만든 건 아니고, 몇 개를 추가해서 open source contribute 를 한 듯하다.

이를 통해 쿼리가 실행되기 전에 테이블이나 컬럼 이름의 존재성을 validation 한다.
Custom udf 를 통해 쿼리를 실행 전에 검증하기도 한다.

### Summary of Presto in Lyft

Lyft 의 presto use case 를 살펴봤다.
왜 Lyft 에서 Presto 를 도입했고, 이용하면서 어떤 문제들이 있었고 이를 해결하기 위해 어떤 방법을 썼는지 잘 보도록 하자.